{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe+pSwd3YiuVzLvSGo3Ci0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhung-chung/ML-Zoomcamp/blob/main/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KwXpErNwnEc",
        "outputId": "12326e47-134f-42ae-f364-0e51c7b11aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "✅ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install additional libraries if needed\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "# Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset directly from the URL\n",
        "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99P1c5IXwnpW",
        "outputId": "8c6cedff-544b-4f6c-bb2d-a8f345fc99ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Dataset shape: (1462, 9)\n",
            "\n",
            "Column names: ['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income', 'employment_status', 'location', 'interaction_count', 'lead_score', 'converted']\n",
            "\n",
            "First 5 rows:\n",
            "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
            "0      paid_ads         NaN                         1        79450.0   \n",
            "1  social_media      retail                         1        46992.0   \n",
            "2        events  healthcare                         5        78796.0   \n",
            "3      paid_ads      retail                         2        83843.0   \n",
            "4      referral   education                         3        85012.0   \n",
            "\n",
            "  employment_status       location  interaction_count  lead_score  converted  \n",
            "0        unemployed  south_america                  4        0.94          1  \n",
            "1          employed  south_america                  1        0.80          0  \n",
            "2        unemployed      australia                  3        0.69          1  \n",
            "3               NaN      australia                  1        0.87          0  \n",
            "4     self_employed         europe                  3        0.62          1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== DATA PREPARATION ===\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values as per homework instructions\n",
        "print(\"\\nHandling missing values...\")\n",
        "\n",
        "# For categorical features, replace with 'NA'\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna('NA')\n",
        "    print(f\"   • {col}: Filled missing values with 'NA'\")\n",
        "\n",
        "# For numerical features, replace with 0.0\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "for col in numerical_cols:\n",
        "    if col != 'converted':  # Don't modify target variable\n",
        "        df[col] = df[col].fillna(0.0)\n",
        "\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"Data preparation completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mrsiKv4wtt6",
        "outputId": "3686f022-b49c-4a86-b0da-75ef5b1bf424"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DATA PREPARATION ===\n",
            "==============================\n",
            "Missing values before cleaning:\n",
            "lead_source                 128\n",
            "industry                    134\n",
            "number_of_courses_viewed      0\n",
            "annual_income               181\n",
            "employment_status           100\n",
            "location                     63\n",
            "interaction_count             0\n",
            "lead_score                    0\n",
            "converted                     0\n",
            "dtype: int64\n",
            "\n",
            "Handling missing values...\n",
            "   • lead_source: Filled missing values with 'NA'\n",
            "   • industry: Filled missing values with 'NA'\n",
            "   • employment_status: Filled missing values with 'NA'\n",
            "   • location: Filled missing values with 'NA'\n",
            "\n",
            "Missing values after cleaning:\n",
            "lead_source                 0\n",
            "industry                    0\n",
            "number_of_courses_viewed    0\n",
            "annual_income               0\n",
            "employment_status           0\n",
            "location                    0\n",
            "interaction_count           0\n",
            "lead_score                  0\n",
            "converted                   0\n",
            "dtype: int64\n",
            "Data preparation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"MACHINE LEARNING ZOOMCAMP 2025 - HOMEWORK 3\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# QUESTION 1: Most frequent industry\n",
        "print(\"\\nQUESTION 1: Most frequent industry\")\n",
        "print(\"-\" * 40)\n",
        "industry_counts = df['industry'].value_counts()\n",
        "industry_mode = df['industry'].mode()\n",
        "print(f\"Industry value counts:\")\n",
        "print(industry_counts)\n",
        "print(f\"\\nAnswer: {industry_mode.iloc[0]}\") # Access the first element of the mode series\n",
        "\n",
        "# QUESTION 2: Feature correlation\n",
        "print(\"\\nQUESTION 2: Feature correlation\")\n",
        "print(\"-\" * 40)\n",
        "numerical_features = ['interaction_count', 'lead_score', 'number_of_courses_viewed', 'annual_income']\n",
        "correlation_matrix = df[numerical_features].corr()\n",
        "\n",
        "print(\"Correlation matrix:\")\n",
        "print(correlation_matrix.round(4))\n",
        "\n",
        "# Check specific pairs\n",
        "pairs = [\n",
        "    ('interaction_count', 'lead_score'),\n",
        "    ('number_of_courses_viewed', 'lead_score'),\n",
        "    ('number_of_courses_viewed', 'interaction_count'),\n",
        "    ('annual_income', 'interaction_count')\n",
        "]\n",
        "\n",
        "print(f\"\\nSpecific pair correlations:\")\n",
        "max_corr = 0\n",
        "max_pair = None\n",
        "\n",
        "for pair in pairs:\n",
        "    # Access the scalar correlation value\n",
        "    corr_val = abs(correlation_matrix.loc[pair[0], pair[1]])\n",
        "    print(f\"{pair[0]} and {pair[1]}: {corr_val:.4f}\")\n",
        "    if corr_val > max_corr:\n",
        "        max_corr = corr_val\n",
        "        max_pair = pair\n",
        "\n",
        "print(f\"\\nAnswer: {max_pair[0]} and {max_pair[1]} (correlation: {max_corr:.4f})\")\n",
        "\n",
        "\n",
        "# Split the data\n",
        "print(\"\\nDATA SPLITTING\")\n",
        "print(\"-\" * 40)\n",
        "X = df.drop('converted', axis=1)\n",
        "y = df['converted']\n",
        "\n",
        "# 60%/20%/20% split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f\"Training set: {X_train.shape} samples ({X_train.shape[0]/len(df)*100:.1f}%)\") # Corrected calculation\n",
        "print(f\"Validation set: {X_val.shape} samples ({X_val.shape[0]/len(df)*100:.1f}%)\") # Corrected calculation\n",
        "print(f\"Test set: {X_test.shape} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")     # Corrected calculation\n",
        "\n",
        "# QUESTION 3: Mutual information\n",
        "print(\"\\nQUESTION 3: Mutual information analysis\")\n",
        "print(\"-\" * 40)\n",
        "categorical_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
        "mutual_info_scores = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    # Ensure X_train[col] is treated as a column vector for mutual_info_classif\n",
        "    X_train_encoded = le.fit_transform(X_train[col]).reshape(-1, 1)\n",
        "    mi_score = mutual_info_classif(X_train_encoded, y_train, random_state=42)[0] # Extract the scalar value\n",
        "    mutual_info_scores[col] = round(mi_score, 2)\n",
        "    print(f\"   • {col}: {mutual_info_scores[col]}\")\n",
        "\n",
        "max_mi_var = max(mutual_info_scores, key=mutual_info_scores.get)\n",
        "print(f\"\\nAnswer: {max_mi_var} (MI score: {mutual_info_scores[max_mi_var]})\")\n",
        "\n",
        "# QUESTION 4: Logistic regression training\n",
        "print(\"\\nQUESTION 4: Logistic regression model\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create model pipeline\n",
        "model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "print(\"Training logistic regression model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_accuracy_rounded = round(val_accuracy, 2)\n",
        "\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Answer: {val_accuracy_rounded}\")\n",
        "\n",
        "# Store original accuracy for Question 5\n",
        "original_accuracy = val_accuracy\n",
        "\n",
        "# QUESTION 5: Feature elimination\n",
        "print(\"\\nQUESTION 5: Feature importance analysis\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
        "feature_differences = {}\n",
        "\n",
        "for feature in features_to_test:\n",
        "    print(f\"Testing removal of: {feature}\")\n",
        "\n",
        "    if feature in categorical_features:\n",
        "        # Remove categorical feature\n",
        "        remaining_categorical = [col for col in categorical_features if col != feature]\n",
        "        remaining_numerical = numerical_features\n",
        "    else:\n",
        "        # Remove numerical feature\n",
        "        remaining_categorical = categorical_features\n",
        "        remaining_numerical = [col for col in numerical_features if col != feature]\n",
        "\n",
        "    # Create new preprocessor\n",
        "    if remaining_categorical and remaining_numerical:\n",
        "        preprocessor_reduced = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', 'passthrough', remaining_numerical),\n",
        "                ('cat', OneHotEncoder(drop='first', sparse_output=False), remaining_categorical)\n",
        "            ])\n",
        "    elif remaining_categorical:\n",
        "        preprocessor_reduced = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('cat', OneHotEncoder(drop='first', sparse_output=False), remaining_categorical)\n",
        "            ])\n",
        "    else:\n",
        "        preprocessor_reduced = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', 'passthrough', remaining_numerical)\n",
        "            ])\n",
        "\n",
        "    # Train model without feature\n",
        "    model_reduced = Pipeline([\n",
        "        ('preprocessor', preprocessor_reduced),\n",
        "        ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Select only the relevant columns for training\n",
        "    X_train_reduced = X_train[remaining_numerical + remaining_categorical]\n",
        "    model_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "    # Select only the relevant columns for prediction\n",
        "    X_val_reduced = X_val[remaining_numerical + remaining_categorical]\n",
        "    y_val_pred_reduced = model_reduced.predict(X_val_reduced)\n",
        "    accuracy_reduced = accuracy_score(y_val, y_val_pred_reduced)\n",
        "\n",
        "\n",
        "    difference = original_accuracy - accuracy_reduced\n",
        "    feature_differences[feature] = difference\n",
        "\n",
        "    print(f\"   Accuracy without {feature}: {accuracy_reduced:.4f}\")\n",
        "    print(f\"   Difference: {difference:.4f}\")\n",
        "\n",
        "# Find the feature whose removal resulted in the smallest difference (i.e., largest accuracy)\n",
        "min_diff_feature = min(feature_differences, key=feature_differences.get)\n",
        "print(f\"\\nAnswer: {min_diff_feature} (difference: {feature_differences[min_diff_feature]:.4f})\")\n",
        "\n",
        "# QUESTION 6: Regularization\n",
        "print(\"\\nQUESTION 6: Regularization analysis\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "C_results = {}\n",
        "\n",
        "for C in C_values:\n",
        "    print(f\"Testing C = {C}\")\n",
        "\n",
        "    model_reg = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42))\n",
        "    ])\n",
        "\n",
        "    model_reg.fit(X_train, y_train)\n",
        "    y_val_pred_reg = model_reg.predict(X_val)\n",
        "    accuracy_reg = accuracy_score(y_val, y_val_pred_reg)\n",
        "    accuracy_reg_rounded = round(accuracy_reg, 3)\n",
        "\n",
        "    C_results[C] = accuracy_reg_rounded\n",
        "    print(f\"   Accuracy: {accuracy_reg_rounded}\")\n",
        "\n",
        "# Find best C (smallest if tied)\n",
        "best_accuracy = max(C_results.values())\n",
        "best_C_values = [C for C, acc in C_results.items() if acc == best_accuracy]\n",
        "best_C = min(best_C_values)\n",
        "\n",
        "print(f\"\\nBest accuracy: {best_accuracy}\")\n",
        "print(f\"Answer: {best_C}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zgkj8BSxJJo",
        "outputId": "c08f93a3-c60f-4c69-f2cd-9ef6df59ef02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MACHINE LEARNING ZOOMCAMP 2025 - HOMEWORK 3\n",
            "==================================================\n",
            "\n",
            "QUESTION 1: Most frequent industry\n",
            "----------------------------------------\n",
            "Industry value counts:\n",
            "industry\n",
            "retail           203\n",
            "finance          200\n",
            "other            198\n",
            "healthcare       187\n",
            "education        187\n",
            "technology       179\n",
            "manufacturing    174\n",
            "NA               134\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Answer: retail\n",
            "\n",
            "QUESTION 2: Feature correlation\n",
            "----------------------------------------\n",
            "Correlation matrix:\n",
            "                          interaction_count  lead_score  \\\n",
            "interaction_count                    1.0000      0.0099   \n",
            "lead_score                           0.0099      1.0000   \n",
            "number_of_courses_viewed            -0.0236     -0.0049   \n",
            "annual_income                        0.0270      0.0156   \n",
            "\n",
            "                          number_of_courses_viewed  annual_income  \n",
            "interaction_count                          -0.0236         0.0270  \n",
            "lead_score                                 -0.0049         0.0156  \n",
            "number_of_courses_viewed                    1.0000         0.0098  \n",
            "annual_income                               0.0098         1.0000  \n",
            "\n",
            "Specific pair correlations:\n",
            "interaction_count and lead_score: 0.0099\n",
            "number_of_courses_viewed and lead_score: 0.0049\n",
            "number_of_courses_viewed and interaction_count: 0.0236\n",
            "annual_income and interaction_count: 0.0270\n",
            "\n",
            "Answer: annual_income and interaction_count (correlation: 0.0270)\n",
            "\n",
            "DATA SPLITTING\n",
            "----------------------------------------\n",
            "Training set: (876, 8) samples (59.9%)\n",
            "Validation set: (293, 8) samples (20.0%)\n",
            "Test set: (293, 8) samples (20.0%)\n",
            "\n",
            "QUESTION 3: Mutual information analysis\n",
            "----------------------------------------\n",
            "   • industry: 0.0\n",
            "   • location: 0.01\n",
            "   • lead_source: 0.0\n",
            "   • employment_status: 0.01\n",
            "\n",
            "Answer: location (MI score: 0.01)\n",
            "\n",
            "QUESTION 4: Logistic regression model\n",
            "----------------------------------------\n",
            "Training logistic regression model...\n",
            "Validation accuracy: 0.7304\n",
            "Answer: 0.73\n",
            "\n",
            "QUESTION 5: Feature importance analysis\n",
            "----------------------------------------\n",
            "Testing removal of: industry\n",
            "   Accuracy without industry: 0.7304\n",
            "   Difference: 0.0000\n",
            "Testing removal of: employment_status\n",
            "   Accuracy without employment_status: 0.7338\n",
            "   Difference: -0.0034\n",
            "Testing removal of: lead_score\n",
            "   Accuracy without lead_score: 0.7338\n",
            "   Difference: -0.0034\n",
            "\n",
            "Answer: employment_status (difference: -0.0034)\n",
            "\n",
            "📊 QUESTION 6: Regularization analysis\n",
            "----------------------------------------\n",
            "🔍 Testing C = 0.01\n",
            "   Accuracy: 0.734\n",
            "🔍 Testing C = 0.1\n",
            "   Accuracy: 0.73\n",
            "🔍 Testing C = 1\n",
            "   Accuracy: 0.73\n",
            "🔍 Testing C = 10\n",
            "   Accuracy: 0.73\n",
            "🔍 Testing C = 100\n",
            "   Accuracy: 0.73\n",
            "\n",
            "Best accuracy: 0.734\n",
            "Answer: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzFy2d5OxWhI"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}